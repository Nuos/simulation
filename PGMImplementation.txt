This document covers the implementation details and challenges/questions for the transition from planetary mesh-based approach to a PGM-based approach. The implementation for this transition will be mainly derived from "Projective Grid Mapping for Planetary Terrain" by Joseph Mahsman.

Goals:
------
* proper texturing of closed surfaces : resolve problem at poles and at IDL (normals)
* multiple frustum rendering
* proper LOD for planetary rendering
* multiple dataset inclusion (high-res & low-res; polar & equirectangular)

Extensions:
-----------
* Proper dataset determination : checking the right datasets
* Streaming only the relevant chunks of the datasets (for very large datasets)
* Extension to allow planetary ocean rendering based on PGM
* Allow height determination for collision detectino
* rendering atmosphere & clouds this way?

Algorithm Functional Blocks:
----------------------------
* PGM
  * Requires: (view-dependent)
    * reference sphere(s) : primary and secondary reference spheres
    * sampling camera
  * Produces:
    * sphere normals 
    * positions
  * Create gridpoints which span the viewport
  * Computes ray-sphere intersection point & sphere intersection normal
    * gamma1 = asin((d/r) sin w) - w : first intersection angle from nadir
    * gamma2 = -asin((d/r) sin w)- w + pi : second intersection angle from nadir
  * pertinent area
    * occluded area (beyond horizon and determined by maximum height)
    * non-sampled intersecting area (below the frustum but should displace into the frustum)
  * Reference Spheres
  	* Primary and secondary (used for occluded area) only differ by radius
  	* Calculation of radii occurs on GPU before PGM
  	* Primary Reference Sphere:
  	  * radius calculated as minimum visible radius from previous frame?
  	    * using a mimimum mipmap operation on the gpu
  	    * final minimum read back to CPU and saved for next frame
  	* Secondary Reference Sphere:
  	  * tangent ray angle to primary sphere : tau
  	  * extent of occluded area is defined by maximum possible normal angle on maximum sphere
  	  	* gamma0 = -asin((d/rmax) sin tau) - tau + pi
  	  * secondary sphere radius : rs = d * cos(gamma0)
  	  * can replace the planet with an impostor when returned radius for secondary sphere is negative
  * Sampling Camera:
    * eye space : relative to camera; view matrix transforms from world-space to eye-space
    * projection matrix transforms points from eye-space into canonical view volume:
      * frustum (field of view, aspect ratio, near plane, far plane) becomes cube
      * all visible objects exist in the cube defined by (-1,-1,-1) and (1,1,1)
    * sampling camera has same position as view camera, but different orientation and frustum
    * sampling frustum contains parts of sphere that should be sampled
    * need to find 3 basis vectors which define sampling camera orientation & matrix
    * need to find frustum attributes to get projection matrix 
      * inverse of projection matrix is used by PGM to convert grid point to eye ray
    * calculate the corner rays of the view frustum and the visible sphere frustum
      * view frustum : easy, just use near, left, right, top, bottom
      * visible sphere frustum : 
        * calculate orientation difference from view frustum
          * backward vector : b = -n (nadir)
          * right vector : r = ||n x f|| (f = camera forward vector)
          * up vector : u = ||r x n||
        * central axis of frustum is nadir
* Height Composition
  * produces accumulated heights based on all height datasets for each projected grid point
  * uses sphere normals to sample datasets
* Rasterization
  * uses accumulated heights to displace mesh and render
* Color Composition
  * accumulates colors and surface normals
* Atmosphere, lighting, etc.

Questions:
----------
* How well does this work at long range?
* Can it automatically scale the number of grid points based on distance?

Unresolved Issues:
------------------